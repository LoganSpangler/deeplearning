{
  "paragraphs": [
    {
      "text": "%md\n### Machine Learning \n\nThis notebook walks you through a simple example of building a simple linear model.\nWe will introduce the concept of Variable and use to do some simple calculations.\nYou will learn\n* **Initialize Weight and bias Variables**\n* **Difference between Variables and Constants**\n* **Globally initialize Variables**\n* **Create a Session**\n* **Create a simple loss function**\n\nThe below example shows a Linear model of how we can model a function that can predict the relationship between Outside temperature and the ice-cream sold.\nThis graph is just a representation of what a linear model looks like\n\n![Linear Model Graph](https://2.bp.blogspot.com/-Ae16jkCOKgs/Vbu8OCl7mlI/AAAAAAAACNM/jWaJJeMf7Ro/s1600/LinearModel.png)\n\nA linear function can be written in the format of \n\n    y \u003d mx + b\n    \n    m \u003d Slope of the line\n    b \u003d offset\n    \nIn Machine learning we try to derive a function looking at the data that best fits data without much bias. \n\nAn excellent course by Andrew Ng, can be found on [Coursera Machine Learning](https://www.coursera.org/learn/machine-learning).\n\n\n![Andrew Ng](https://www.cmu.edu/silicon-valley/news-events/dls/2014/images/andrewng-headshot.png)\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 4:21:15 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495164071833_-603996952",
      "id": "20170519-032111_1021636815",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eMachine Learning\u003c/h3\u003e\n\u003cp\u003eThis notebook walks you through a simple example of building a simple linear model.\n\u003cbr  /\u003eWe will introduce the concept of Variable and use to do some simple calculations.\n\u003cbr  /\u003eYou will learn\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInitialize Weight and bias Variables\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDifference between Variables and Constants\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGlobally initialize Variables\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreate a Session\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCreate a simple loss function\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe below example shows a Linear model of how we can model a function that can predict the relationship between Outside temperature and the ice-cream sold.\n\u003cbr  /\u003eThis graph is just a representation of what a linear model looks like\u003c/p\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://2.bp.blogspot.com/-Ae16jkCOKgs/Vbu8OCl7mlI/AAAAAAAACNM/jWaJJeMf7Ro/s1600/LinearModel.png\" alt\u003d\"Linear Model Graph\" /\u003e\u003c/p\u003e\n\u003cp\u003eA linear function can be written in the format of\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ey \u003d mx + b\n\nm \u003d Slope of the line\nb \u003d offset\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn Machine learning we try to derive a function looking at the data that best fits data without much bias.\u003c/p\u003e\n\u003cp\u003eAn excellent course by Andrew Ng, can be found on \u003ca href\u003d\"https://www.coursera.org/learn/machine-learning\"\u003eCoursera Machine Learning\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://www.cmu.edu/silicon-valley/news-events/dls/2014/images/andrewng-headshot.png\" alt\u003d\"Andrew Ng\" /\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "May 19, 2017 3:21:11 AM",
      "dateStarted": "May 19, 2017 3:42:55 AM",
      "dateFinished": "May 19, 2017 3:42:55 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nIn *Machine Learning* we often denote weights by variable **W** and offset by **b**. A sample equation that we would like to build is\n\n    y \u003d W*x + b\n\nWhere **W** is the weights and **b** is the bias.\n\nWhat we would like to do is to look at all the input values create a function that can be used to predict future values of y.\n\n\n    W \u003d tf.Variable([.001], tf.float32)\n    b \u003d tf.Variable([-.0001], tf.float32)\n    input_training_values \u003d tf.placeholder(tf.float32)\n    \n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 4:06:20 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495164527308_147648036",
      "id": "20170519-032847_334463211",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eIn \u003cem\u003eMachine Learning\u003c/em\u003e we often denote weights by variable \u003cstrong\u003eW\u003c/strong\u003e and offset by \u003cstrong\u003eb\u003c/strong\u003e. A sample equation that we would like to build is\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ey \u003d W*x + b\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhere \u003cstrong\u003eW\u003c/strong\u003e is the weights and \u003cstrong\u003eb\u003c/strong\u003e is the bias.\u003c/p\u003e\n\u003cp\u003eWhat we would like to do is to look at all the input values create a function that can be used to predict future values of y.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eW \u003d tf.Variable([.001], tf.float32)\nb \u003d tf.Variable([-.0001], tf.float32)\ninput_training_values \u003d tf.placeholder(tf.float32)\n\u003c/code\u003e\u003c/pre\u003e\n"
      },
      "dateCreated": "May 19, 2017 3:28:47 AM",
      "dateStarted": "May 19, 2017 4:06:07 AM",
      "dateFinished": "May 19, 2017 4:06:07 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Constants vs Variables\n\n- Constants  are initialized when you call [tf.constant](https://www.tensorflow.org/api_guides/python/constant_op), and their value can never change.\n- By contrast, variables are not initialized when you call [tf.Variable](https://www.tensorflow.org/api_docs/python/tf/Variable). To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:\n\nExample\n\n    init \u003d tf.global_variables_initializer()\n    sess.run(init)\n\nIt is important to realize init is a handle to the TensorFlow sub-graph that initializes all the global variables. Until we call sess.run, the variables are uninitialized.\n\u003cbr/\u003e\n**In the below section we run some code to reach this far**:-\n\u003cbr/\u003e\n    \n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 4:21:03 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495166767271_-1748390731",
      "id": "20170519-040607_969344010",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eConstants vs Variables\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eConstants  are initialized when you call \u003ca href\u003d\"https://www.tensorflow.org/api_guides/python/constant_op\"\u003etf.constant\u003c/a\u003e, and their value can never change.\u003c/li\u003e\n\u003cli\u003eBy contrast, variables are not initialized when you call \u003ca href\u003d\"https://www.tensorflow.org/api_docs/python/tf/Variable\"\u003etf.Variable\u003c/a\u003e. To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eExample\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003einit \u003d tf.global_variables_initializer()\nsess.run(init)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIt is important to realize init is a handle to the TensorFlow sub-graph that initializes all the global variables. Until we call sess.run, the variables are uninitialized.\n\u003cbr  /\u003e\u003cbr /\u003e\n\u003cbr  /\u003e\u003cstrong\u003eIn the below section we run some code to reach this far\u003c/strong\u003e:-\n\u003cbr  /\u003e\u003cbr /\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "May 19, 2017 4:06:07 AM",
      "dateStarted": "May 19, 2017 4:20:47 AM",
      "dateFinished": "May 19, 2017 4:20:47 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n#Import tensorflow package\n\nimport tensorflow as tf\n\n#Initialize Weights\n\nW \u003d tf.Variable([.001], tf.float32)\nb \u003d tf.Variable([-.0001], tf.float32)\n\n#Create a placeholder to pass the values of the input values or x and y\n\n# Model input and output\nx \u003d tf.placeholder(tf.float32)\ny \u003d tf.placeholder(tf.float32)\n\n#Model Linear finction\nlinear_function \u003d W*x + b\n\n#Create the Session\nsess \u003d tf.Session()\n\n#Globally initialize the variables\ninit \u003d tf.global_variables_initializer()\n\n#At this step you have to explicitly run it to initialize the variables\nsess.run(init)\n\n\n\n\n\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:21:14 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495166919329_-1056799388",
      "id": "20170519-040839_1629676984",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "2017-05-19 22:21:16.352108: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-19 22:21:16.352143: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n2017-05-19 22:21:16.352150: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n"
      },
      "dateCreated": "May 19, 2017 4:08:39 AM",
      "dateStarted": "May 19, 2017 10:21:14 PM",
      "dateFinished": "May 19, 2017 10:21:16 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nSince **x** is a placeholder, we can evaluate linear_model for several values of *x* simultaneously as follows:\n    print(sess.run(linear_function, {x:[1,2,3,4,5,6,7,8,9,10,22,25,28]}))\n\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 4:23:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495167213316_1217665899",
      "id": "20170519-041333_311373110",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eSince \u003cstrong\u003ex\u003c/strong\u003e is a placeholder, we can evaluate linear_model for several values of \u003cem\u003ex\u003c/em\u003e simultaneously as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eprint(sess.run(linear_function, {x:[1,2,3,4,5,6,7,8,9,10,22,25,28]}))\n\u003c/code\u003e\u003c/pre\u003e\n"
      },
      "dateCreated": "May 19, 2017 4:13:33 AM",
      "dateStarted": "May 19, 2017 4:23:52 AM",
      "dateFinished": "May 19, 2017 4:23:52 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nprint(sess.run(linear_function, {x:[1,2,3,4,5,6,7,8,9,10,22,25,28]}))",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:21:22 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495167748425_2059674925",
      "id": "20170519-042228_762787845",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "[ 0.0009  0.0019  0.0029  0.0039  0.0049  0.0059  0.0069  0.0079  0.0089\n  0.0099  0.0219  0.0249  0.0279]\n"
      },
      "dateCreated": "May 19, 2017 4:22:28 AM",
      "dateStarted": "May 19, 2017 10:21:22 PM",
      "dateFinished": "May 19, 2017 10:21:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nIn the above example you can see a sample linear function that got executed!\n\nGreat!! Success.\n\nNow you know to write \n* a simple Tensorflow Graph \n* Create Variables\n* Create Placeholders\n* Create a Session\n* Initialize Variables\n* Execute a Simple Liner Function Graph by passing values to it.\n\nNow you can play around with various values and see a simple tensorflow graph in action",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 9:43:50 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495167813031_386694763",
      "id": "20170519-042333_111627552",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eIn the above example you can see a sample linear function that got executed!\u003c/p\u003e\n\u003cp\u003eGreat!! Success.\u003c/p\u003e\n\u003cp\u003eNow you know to write\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ea simple Tensorflow Graph\u003c/li\u003e\n\u003cli\u003eCreate Variables\u003c/li\u003e\n\u003cli\u003eCreate Placeholders\u003c/li\u003e\n\u003cli\u003eCreate a Session\u003c/li\u003e\n\u003cli\u003eInitialize Variables\u003c/li\u003e\n\u003cli\u003eExecute a Simple Liner Function Graph by passing values to it.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow you can play around with various values and see a simple tensorflow graph in action\u003c/p\u003e\n"
      },
      "dateCreated": "May 19, 2017 4:23:33 AM",
      "dateStarted": "May 19, 2017 9:28:46 PM",
      "dateFinished": "May 19, 2017 9:28:47 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n\u003cp line-height\u003d1100%\u003e\n\u003cfont size\u003d\"3\" color\u003d\"Green\"\u003eWait!! \u003c/font\u003e The function did not do anything special. It has not learnt anything?? \n\nYou got it \u003cstrong\u003e right!! \u003c/strong\u003e\nThe intelligence was given by us about the \u003cstrong\u003ecode\u003c/strong\u003e. \n\n\u003c/p\u003e\n\n\u003cbr/\u003e\n\n- What we would want to do is to come up with a linear function that learns and corrects the linear line.\n- In the example above we gave the weights and bias a random value of ** 0.001 **\n- Why \u003cstrong\u003e 0.001\u003c/strong\u003e?  No real reason, we are just testing right now.\n\u003cp line-height\u003d120%\u003e\n\nOK! You have followed so far. I have some more theory for you.\n\nWhat we want to do is test with a bunch of sample values of till we get the correct slope that **best fits** the line.\n\u003cbr/\u003e\n\nThe process of finding the best fit line done incremenetally or in steps. The function that will help you get this is called \u003cstrong\u003e Cost Function. \u003c/strong\u003e\n\nThe idea is to find the optimal value of \u003cstrong\u003eW\u003c/strong\u003e and \u003cstrong\u003eb\u003c/strong\u003e so that during training the actual value of \u003cstrong\u003ey\u003c/strong\u003e and \u003cstrong\u003ey\u0026#770;\u003c/strong\u003e for a set of input \u003cstrong\u003ex\u003c/strong\u003e.\n\n![Cost Function](https://wingshore.files.wordpress.com/2014/11/images-12.jpg)\n\u003cbr/\u003e\nBelow short video gives a good introduction to the cost function. This is part of the machine learning tutorial mentioned above.\n[Coursera Course on Cost Function](https://www.coursera.org/learn/machine-learning/lecture/rkTp3/cost-function)\n\u003cbr/\u003e\n\u003c/p\u003e\n\n\n\n\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:20:58 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495218187456_-522487075",
      "id": "20170519-182307_674711846",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp line-height\u003d1100%\u003e\n\u003cfont size\u003d\"3\" color\u003d\"Green\"\u003eWait!! \u003c/font\u003e The function did not do anything special. It has not learnt anything?? \n\nYou got it \u003cstrong\u003e right!! \u003c/strong\u003e\nThe intelligence was given by us about the \u003cstrong\u003ecode\u003c/strong\u003e. \n\n\u003c/p\u003e\n\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat we would want to do is to come up with a linear function that learns and corrects the linear line.\u003c/li\u003e\n\u003cli\u003eIn the example above we gave the weights and bias a random value of \u003cem\u003e\u003c/em\u003e 0.001 \u003cem\u003e\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003eWhy \u003cstrong\u003e 0.001\u003c/strong\u003e?  No real reason, we are just testing right now.\n\u003cbr  /\u003e\u003cp line-height\u003d120%\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOK! You have followed so far. I have some more theory for you.\u003c/p\u003e\n\u003cp\u003eWhat we want to do is test with a bunch of sample values of till we get the correct slope that \u003cstrong\u003ebest fits\u003c/strong\u003e the line.\n\u003cbr  /\u003e\u003cbr /\u003e\u003c/p\u003e\n\u003cp\u003eThe process of finding the best fit line done incremenetally or in steps. The function that will help you get this is called \u003cstrong\u003e Cost Function. \u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThe idea is to find the optimal value of \u003cstrong\u003eW\u003c/strong\u003e and \u003cstrong\u003eb\u003c/strong\u003e so that during training the actual value of \u003cstrong\u003ey\u003c/strong\u003e and \u003cstrong\u003ey\u0026#770;\u003c/strong\u003e for a set of input \u003cstrong\u003ex\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://wingshore.files.wordpress.com/2014/11/images-12.jpg\" alt\u003d\"Cost Function\" /\u003e\n\u003cbr  /\u003e\u003cbr /\u003e\n\u003cbr  /\u003eBelow short video gives a good introduction to the cost function. This is part of the machine learning tutorial mentioned above.\n\u003cbr  /\u003e\u003ca href\u003d\"https://www.coursera.org/learn/machine-learning/lecture/rkTp3/cost-function\"\u003eCoursera Course on Cost Function\u003c/a\u003e\n\u003cbr  /\u003e\u003cbr /\u003e\n\u003cbr  /\u003e\u003c/p\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "May 19, 2017 6:23:07 PM",
      "dateStarted": "May 19, 2017 10:12:00 PM",
      "dateFinished": "May 19, 2017 10:12:00 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nNow that you have seen an example of how a cost function is calculated. Lets plan to implement in **Tensorflow**.\nA loss function measures how far apart the current model is from the provided data. We\u0027ll use a standard loss model for **linear regression**, \n- which sums the squares of the deltas between the current model and the provided data.\n- (linear_function - y) - creates a vector where each element is the corresponding example\u0027s error delta. \n- We call [tf.square](https://www.tensorflow.org/api_docs/python/tf/square) to square that error. \n\nThen, we sum all the squared errors to create a single scalar that abstracts the error of all examples using [tf.reduce_sum](https://www.tensorflow.org/versions/master/api_docs/python/tf/reduce_sum)\n\n\n\n\n    y \u003d tf.placeholder(tf.float32)\n    squared_deltas \u003d tf.square(linear_function - y)\n    loss \u003d tf.reduce_sum(squared_deltas)\n    print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n    \n\n\u003cbr/\u003e\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:19:18 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495229650937_-334900263",
      "id": "20170519-213410_790083910",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eNow that you have seen an example of how a cost function is calculated. Lets plan to implement in \u003cstrong\u003eTensorflow\u003c/strong\u003e.\n\u003cbr  /\u003eA loss function measures how far apart the current model is from the provided data. We\u0027ll use a standard loss model for \u003cstrong\u003elinear regression\u003c/strong\u003e,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ewhich sums the squares of the deltas between the current model and the provided data.\u003c/li\u003e\n\u003cli\u003e(linear_function - y) - creates a vector where each element is the corresponding example\u0027s error delta.\u003c/li\u003e\n\u003cli\u003eWe call \u003ca href\u003d\"https://www.tensorflow.org/api_docs/python/tf/square\"\u003etf.square\u003c/a\u003e to square that error.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThen, we sum all the squared errors to create a single scalar that abstracts the error of all examples using \u003ca href\u003d\"https://www.tensorflow.org/versions/master/api_docs/python/tf/reduce_sum\"\u003etf.reduce_sum\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ey \u003d tf.placeholder(tf.float32)\nsquared_deltas \u003d tf.square(linear_function - y)\nloss \u003d tf.reduce_sum(squared_deltas)\nprint(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "May 19, 2017 9:34:10 PM",
      "dateStarted": "May 19, 2017 10:19:05 PM",
      "dateFinished": "May 19, 2017 10:19:05 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ny \u003d tf.placeholder(tf.float32)\nsquared_deltas \u003d tf.square(linear_function - y)\nloss \u003d tf.reduce_sum(squared_deltas)\nprint(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:21:28 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495232023433_-1020135886",
      "id": "20170519-221343_1734641709",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "14.0388\n"
      },
      "dateCreated": "May 19, 2017 10:13:43 PM",
      "dateStarted": "May 19, 2017 10:21:28 PM",
      "dateFinished": "May 19, 2017 10:21:28 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\u003cbr/\u003e\nWe could improve this manually by reassigning the values of W and b to the perfect values of -1 and 1. \n\nA variable is initialized to the value provided to tf.\nVariable but can be changed using operations like tf.assign. \nFor example, W\u003d-1 and b\u003d1 are the optimal parameters for our model. We can change W and b accordingly:\n\n    fixW \u003d tf.assign(W, [-1.])\n    fixb \u003d tf.assign(b, [1.])\n    sess.run([fixW, fixb])\n    print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:23:31 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495232373227_-848231393",
      "id": "20170519-221933_1225378015",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003e\u003cbr /\u003e\n\u003cbr  /\u003eWe could improve this manually by reassigning the values of W and b to the perfect values of -1 and 1.\u003c/p\u003e\n\u003cp\u003eA variable is initialized to the value provided to tf.\n\u003cbr  /\u003eVariable but can be changed using operations like tf.assign.\n\u003cbr  /\u003eFor example, W\u003d-1 and b\u003d1 are the optimal parameters for our model. We can change W and b accordingly:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efixW \u003d tf.assign(W, [-1.])\nfixb \u003d tf.assign(b, [1.])\nsess.run([fixW, fixb])\nprint(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n\u003c/code\u003e\u003c/pre\u003e\n"
      },
      "dateCreated": "May 19, 2017 10:19:33 PM",
      "dateStarted": "May 19, 2017 10:23:31 PM",
      "dateFinished": "May 19, 2017 10:23:31 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\n#Reassigning to the values of W and b\nfixW \u003d tf.assign(W, [-1.])\nfixb \u003d tf.assign(b, [1.])\nsess.run([fixW, fixb])\nprint(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:24:17 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495232516395_880612336",
      "id": "20170519-222156_1392629912",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "0.0\n"
      },
      "dateCreated": "May 19, 2017 10:21:56 PM",
      "dateStarted": "May 19, 2017 10:24:17 PM",
      "dateFinished": "May 19, 2017 10:24:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\u003cbr/\u003e\n\nWow! Now we see a loss of \u003cb\u003e0.0\u003c/b\u003e. \nWe guessed the **\"perfect\"** values of **W and b**, but the whole point of machine learning is to find the correct model parameters automatically. We will show how to accomplish this in the next section.\n\u003cbr/\u003e\n### Optimizers\nA complete discussion of machine learning is out of the scope of this tutorial. However, TensorFlow provides **optimizers** that slowly change each variable in order to minimize the **loss** function. The simplest **optimizer is gradient descent**. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable. In general, computing symbolic derivatives manually is tedious and error-prone. Consequently, **TensorFlow** can **automatically produce derivatives** given only a description of the model using the function [tf.gradients](https://www.tensorflow.org/versions/master/api_docs/python/tf/gradients). For simplicity, optimizers typically do this for you.\n\u003cbr/\u003e\n\n    optimizer \u003d tf.train.GradientDescentOptimizer(0.01)\n    train \u003d optimizer.minimize(loss)\nIn the above example **0.01** is the **learning rate**. Learning rate is the step size as by how much gradients would move down towards the direction of the gradient. These are part of what is called **hyper parameters** which is used to tune a learning algorithm.\n\n    sess.run(init) # reset values to incorrect defaults.\n    for i in range(1000):\n     sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n\n    print(sess.run([W, b]))\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:47:37 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495232657660_1632243121",
      "id": "20170519-222417_1100786038",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003e\u003cbr /\u003e\u003c/p\u003e\n\u003cp\u003eWow! Now we see a loss of \u003cb\u003e0.0\u003c/b\u003e.\n\u003cbr  /\u003eWe guessed the \u003cstrong\u003e\u0026ldquo;perfect\u0026rdquo;\u003c/strong\u003e values of \u003cstrong\u003eW and b\u003c/strong\u003e, but the whole point of machine learning is to find the correct model parameters automatically. We will show how to accomplish this in the next section.\n\u003cbr  /\u003e\u003cbr /\u003e\u003c/p\u003e\n\u003ch3\u003eOptimizers\u003c/h3\u003e\n\u003cp\u003eA complete discussion of machine learning is out of the scope of this tutorial. However, TensorFlow provides \u003cstrong\u003eoptimizers\u003c/strong\u003e that slowly change each variable in order to minimize the \u003cstrong\u003eloss\u003c/strong\u003e function. The simplest \u003cstrong\u003eoptimizer is gradient descent\u003c/strong\u003e. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable. In general, computing symbolic derivatives manually is tedious and error-prone. Consequently, \u003cstrong\u003eTensorFlow\u003c/strong\u003e can \u003cstrong\u003eautomatically produce derivatives\u003c/strong\u003e given only a description of the model using the function \u003ca href\u003d\"https://www.tensorflow.org/versions/master/api_docs/python/tf/gradients\"\u003etf.gradients\u003c/a\u003e. For simplicity, optimizers typically do this for you.\n\u003cbr  /\u003e\u003cbr /\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eoptimizer \u003d tf.train.GradientDescentOptimizer(0.01)\ntrain \u003d optimizer.minimize(loss)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn the above example \u003cstrong\u003e0.01\u003c/strong\u003e is the \u003cstrong\u003elearning rate\u003c/strong\u003e. Learning rate is the step size as by how much gradients would move down towards the direction of the gradient. These are part of what is called \u003cstrong\u003ehyper parameters\u003c/strong\u003e which is used to tune a learning algorithm.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esess.run(init) # reset values to incorrect defaults.\nfor i in range(1000):\n sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n\nprint(sess.run([W, b]))\n\u003c/code\u003e\u003c/pre\u003e\n"
      },
      "dateCreated": "May 19, 2017 10:24:17 PM",
      "dateStarted": "May 19, 2017 10:47:37 PM",
      "dateFinished": "May 19, 2017 10:47:37 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n\noptimizer \u003d tf.train.GradientDescentOptimizer(0.01)\ntrain \u003d optimizer.minimize(loss)\n\nsess.run(init) # reset values to incorrect defaults.\nfor i in range(1000):\n sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n\n\nprint(sess.run([W, b]))\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:53:36 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495232724700_65986188",
      "id": "20170519-222524_549899529",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "[array([-0.99999768], dtype\u003dfloat32), array([ 0.99999309], dtype\u003dfloat32)]\n"
      },
      "dateCreated": "May 19, 2017 10:25:24 PM",
      "dateStarted": "May 19, 2017 10:53:11 PM",
      "dateFinished": "May 19, 2017 10:53:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nSo you can see\n    \n    [array([-0.99999768], dtype\u003dfloat32), array([ 0.99999309], dtype\u003dfloat32)]\nEven with a small dataset it got pretty close to ideal weights of **W~\u003d-1.** and **b~\u003d1.**\n\n\nNow we have done actual machine learning! Although doing this simple linear regression doesn\u0027t require much TensorFlow core code, more complicated models and methods to feed data into your model necessitate more code.\n\n\n\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:59:22 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495234080839_60934070",
      "id": "20170519-224800_1306739864",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eSo you can see\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e[array([-0.99999768], dtype\u003dfloat32), array([ 0.99999309], dtype\u003dfloat32)]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEven with a small dataset it got pretty close to ideal weights of \u003cstrong\u003eW~\u003d-1.\u003c/strong\u003e and \u003cstrong\u003eb~\u003d1.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNow we have done actual machine learning! Although doing this simple linear regression doesn\u0027t require much TensorFlow core code, more complicated models and methods to feed data into your model necessitate more code.\u003c/p\u003e\n"
      },
      "dateCreated": "May 19, 2017 10:48:00 PM",
      "dateStarted": "May 19, 2017 10:56:02 PM",
      "dateFinished": "May 19, 2017 10:56:02 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### The Complete code\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:59:17 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495234435884_1558298524",
      "id": "20170519-225355_1572541424",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003eThe Complete code\u003c/h3\u003e\n"
      },
      "dateCreated": "May 19, 2017 10:53:55 PM",
      "dateStarted": "May 19, 2017 10:59:17 PM",
      "dateFinished": "May 19, 2017 10:59:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nimport numpy as np\nimport tensorflow as tf\n\n# Model parameters\nW \u003d tf.Variable([.3], tf.float32)\nb \u003d tf.Variable([-.3], tf.float32)\n# Model input and output\nx \u003d tf.placeholder(tf.float32)\nlinear_model \u003d W * x + b\ny \u003d tf.placeholder(tf.float32)\n# loss\nloss \u003d tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n# optimizer\noptimizer \u003d tf.train.GradientDescentOptimizer(0.01)\ntrain \u003d optimizer.minimize(loss)\n# training data\nx_train \u003d [1,2,3,4]\ny_train \u003d [0,-1,-2,-3]\n# training loop\ninit \u003d tf.global_variables_initializer()\nsess \u003d tf.Session()\nsess.run(init) # reset values to wrong\nfor i in range(1000):\n  sess.run(train, {x:x_train, y:y_train})\n\n# evaluate training accuracy\ncurr_W, curr_b, curr_loss  \u003d sess.run([W, b, loss], {x:x_train, y:y_train})\nprint(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 10:59:21 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495234736921_-974658372",
      "id": "20170519-225856_1503688828",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
      },
      "dateCreated": "May 19, 2017 10:58:56 PM",
      "dateStarted": "May 19, 2017 10:59:21 PM",
      "dateFinished": "May 19, 2017 10:59:21 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### \u003d\u003d\u003d\u003d Finish \u003d\u003d\u003d\n\n",
      "user": "sdutta@qubole.com",
      "dateUpdated": "May 19, 2017 11:00:25 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495234761223_-1942655956",
      "id": "20170519-225921_1584937434",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch3\u003e\u003d\u003d\u003d\u003d Finish \u003d\u003d\u003d\u003c/h3\u003e\n"
      },
      "dateCreated": "May 19, 2017 10:59:21 PM",
      "dateStarted": "May 19, 2017 11:00:23 PM",
      "dateFinished": "May 19, 2017 11:00:23 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1495234809746_-1947617176",
      "id": "20170519-230009_534390804",
      "dateCreated": "May 19, 2017 11:00:09 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Tensorflow_Hello_World_Part2",
  "id": "SNHYKES2TX1495164070",
  "angularObjects": {
    "2CGJHK7F9314001495154604096": [],
    "2CHP5KFXT314001495154604098": [],
    "2CGD7416V314001495154604088": [],
    "2CK3WZ7YJ314001495154727302": []
  },
  "config": {},
  "info": {},
  "source": "FCN"
}